{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORD EMBEDDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in c:\\users\\kevin\\anaconda3\\lib\\site-packages (0.14.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:/Users/kevin/0_projet_satisfaction_client/10_Streamlit/reviews_trust.csv\")\n",
    "df = df[[\"Commentaire\", \"star\"]]\n",
    "df[\"Sentiment\"] = df[\"star\"].apply(lambda x : np.where(x >=4 , 1 , 0))  # ajout de la colonne Sentiment à df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppression des valeurs manquantes de la colonne Commentaire\n",
    "df = df.dropna(axis = 0, how = 'any', subset =[\"Commentaire\"])\n",
    "df.reset_index(inplace = True)\n",
    "df = df.drop(['index','star'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"preprocessed\"] = df[\"Commentaire\"]\n",
    "\n",
    "#séparation des données pour l'analyse des sentiments\n",
    "X = df.drop([\"Commentaire\", \"Sentiment\"] , axis=1)\n",
    "y = df[\"Sentiment\"]\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size = 0.8, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\kevin\\anaconda3\\lib\\site-packages (4.2.0)\n",
      "Requirement already satisfied: Cython==0.29.28 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from gensim) (0.29.28)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from gensim) (1.21.6)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\kevin\\anaconda3\\lib\\site-packages (from gensim) (6.0.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessed_class_word2vec import comment_cleaner\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pipeline_w2v import GensimWord2VecVectorizer\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durée d'entraînement : 0.0 secondes\n"
     ]
    }
   ],
   "source": [
    "# Best score training\n",
    "from joblib import dump, load\n",
    "import time\n",
    "\n",
    "####\n",
    "#tfidf - LOGREG\n",
    "start = time.time()\n",
    "clf_lr_w2v = LogisticRegression(max_iter= 10000, C = 10, penalty = 'l2', solver = 'liblinear')\n",
    "end = time.time()\n",
    "print(\"Durée d'entraînement :\", end - start, \"secondes\")\n",
    "\n",
    "scaler = MaxAbsScaler()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# pipe W2v - regression logistique\n",
    "pipe_w2v_lr = Pipeline(steps=[\n",
    "    ('clean_comment',comment_cleaner()),\n",
    "    ('vectorizer', GensimWord2VecVectorizer()),\n",
    "    ('scaler', scaler),\n",
    "    ('classifieur',clf_lr_w2v)], \n",
    "    verbose= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ..... (step 1 of 4) Processing clean_comment, total=   8.5s\n",
      "[Pipeline] ........ (step 2 of 4) Processing vectorizer, total=   3.9s\n",
      "[Pipeline] ............ (step 3 of 4) Processing scaler, total=   0.0s\n",
      "[Pipeline] ....... (step 4 of 4) Processing classifieur, total=   0.8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('clean_comment', comment_cleaner()),\n",
       "                ('vectorizer',\n",
       "                 GensimWord2VecVectorizer(hs=0, min_count=2, negative=10,\n",
       "                                          seed=34, sg=1, vector_size=200,\n",
       "                                          window=5, workers=-1)),\n",
       "                ('scaler', MaxAbsScaler(copy=True)),\n",
       "                ('classifieur',\n",
       "                 LogisticRegression(C=10, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=10000,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='liblinear', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.array(X_train)\n",
    "pipe_w2v_lr.fit(X_train.reshape(-1,1),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_test)\n",
    "y_pred = pipe_w2v_lr.predict(X_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82      1652\n",
      "           1       0.88      0.84      0.86      2315\n",
      "\n",
      "    accuracy                           0.84      3967\n",
      "   macro avg       0.84      0.84      0.84      3967\n",
      "weighted avg       0.85      0.84      0.84      3967\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/kevin/0_projet_satisfaction_client/10_Streamlit/code_pour_streamlit/joblib_file/pipe_w2v_lr.pkl']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best score training\n",
    "from joblib import dump, load\n",
    "import time\n",
    "\n",
    "\n",
    "joblib_file = \"C:/Users/kevin/0_projet_satisfaction_client/10_Streamlit/code_pour_streamlit/joblib_file/pipe_w2v_lr.pkl\"\n",
    "dump(pipe_w2v_lr, joblib_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WORD2VEC UNIQUEMENT pour les modèles REGRESSION LOG / RANDOM FOREST / et Mulitonomial Naïve Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REGRESSION LOGISTIQUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X = df.drop(['Commentaire', 'Sentiment','preprocessed'], axis=1)\n",
    "mms = MinMaxScaler()\n",
    "X = pd.concat([wordvec_df, X], axis=1)\n",
    "X = pd.DataFrame(mms.fit_transform(X), columns= X.columns)\n",
    "y = df[\"Sentiment\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size = 0.8, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = LogisticRegression(max_iter= 500)\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "penalty = ['l2']\n",
    "C = [0.01,0.1,1,10,100,120]\n",
    "grid = dict(solver=solvers,penalty=penalty,C=C)\n",
    "# define grid search\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=5, scoring='accuracy')\n",
    "grid_lr = grid_search.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_lr.best_score_, grid_lr.best_params_))\n",
    "means = grid_lr.cv_results_['mean_test_score']\n",
    "stds = grid_lr.cv_results_['std_test_score']\n",
    "params = grid_lr.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print ('Train Accuracy: %.2f'%grid_lr.score(X_train, y_train))\n",
    "print ('Test Accuracy: %.2f'%grid_lr.score(X_test, y_test))\n",
    "\n",
    "pred = grid_lr.predict(X_test)\n",
    "\n",
    "crosstab = pd.crosstab(y_test, pred, rownames=[\"classe réelle\"], colnames=[\"classe prédite\"])\n",
    "print(crosstab)\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.heatmap(crosstab, annot=True, cmap='PuOr');\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "print(\" -- Linear regression optimized --\")\n",
    "pred = grid_lr.predict(X_test)\n",
    "display(pd.crosstab(y_test, pred,  colnames=[\"Classe réelle\"], rownames=[\"Classe prédite\"]))\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#roc curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "pred_probas = grid_lr.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "fpr,tpr,_ = roc_curve(y_test, pred_probas)\n",
    "roc_auc = auc(fpr,tpr)\n",
    "plt.plot(fpr,tpr,label='area = %.2f' %roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomFOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "param_grid = {'max_depth': [5, 10, None], 'max_features': ['auto', 'log2'], 'n_estimators': [5, 6, 7, 8, 9, 10, 11, 12, 13, 15,100,110,130]}\n",
    "# define grid search\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=5, scoring='accuracy')\n",
    "grid_rf = grid_search.fit(X_train, y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_rf.best_score_, grid_rf.best_params_))\n",
    "means = grid_rf.cv_results_['mean_test_score']\n",
    "stds = grid_rf.cv_results_['std_test_score']\n",
    "params = grid_rf.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print ('Train Accuracy: %.2f'%grid_lr.score(X_train, y_train))\n",
    "print ('Test Accuracy: %.2f'%grid_lr.score(X_test, y_test))\n",
    "\n",
    "pred = grid_rf.predict(X_test)\n",
    "\n",
    "crosstab = pd.crosstab(y_test, pred, rownames=[\"classe réelle\"], colnames=[\"classe prédite\"])\n",
    "print(crosstab)\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.heatmap(crosstab, annot=True, cmap='PuOr');\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "print(\" -- Linear regression optimized --\")\n",
    "pred = grid_rf.predict(X_test)\n",
    "display(pd.crosstab(y_test, pred,  colnames=[\"Classe réelle\"], rownames=[\"Classe prédite\"]))\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#roc curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "pred_probas = grid_rf.predict_proba(X_test)[:,1]\n",
    "\n",
    "\n",
    "fpr,tpr,_ = roc_curve(y_test, pred_probas)\n",
    "roc_auc = auc(fpr,tpr)\n",
    "plt.plot(fpr,tpr,label='area = %.2f' %roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Multinomial Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = MultinomialNB()\n",
    "params = {\"alpha\": np.linspace(1e-10,1,30)}\n",
    "grid_MN = GridSearchCV(MultinomialNB(), cv= 5, param_grid = params)\n",
    "grid_MN.fit(X_train, y_train)\n",
    "print(\"Meilleur paramètre : \", grid_MN.best_params_, \"permettant d'obtenir un score de \" , grid_MN.best_score_)\n",
    "print(\"Score sur le trainset :\",grid_MN.score(X_train,y_train),\"; Score sur le testset : \",grid_MN.score(X_test,y_test))\n",
    "print(\"On ne fait à priori pas face à un problème d'overfiting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_MNB = grid_MN.predict_proba(X_test)\n",
    "from sklearn.metrics import auc, roc_curve\n",
    "\n",
    "fpr , tpr , seuil = roc_curve(y_test, y_pred_MNB[:,1], pos_label= 1)\n",
    "aucf= auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, color='coral', lw=2, label ='auc=%1.5f' % aucf)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title(\"-- Multinomial Naïve Bayes ROC CURVE --\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('1 - specificite (Taux de FN)', fontsize=14)\n",
    "plt.ylabel('Sensibilite (Taux de VP)', fontsize=14)\n",
    "plt.legend();\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print ('Train Accuracy: %.2f'%grid_MN.score(X_train, y_train))\n",
    "print ('Test Accuracy: %.2f'%grid_MN.score(X_test, y_test))\n",
    "\n",
    "from sklearn.metrics import classification_report \n",
    "\n",
    "pred = grid_MN.predict(X_test)\n",
    "\n",
    "crosstab = pd.crosstab(y_test, pred, rownames=[\"classe réelle\"], colnames=[\"classe prédite\"])\n",
    "print(crosstab)\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.heatmap(crosstab, annot=True, cmap='PuOr');\n",
    "print(classification_report(y_test, pred))\n",
    "\n",
    "print(\" -- Multinomial naive baies optimized --\")\n",
    "pred = grid_MN.predict(X_test)\n",
    "display(pd.crosstab(y_test, pred,  colnames=[\"Classe réelle\"], rownames=[\"Classe prédite\"]))\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(model_w2v.wv.index_to_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
